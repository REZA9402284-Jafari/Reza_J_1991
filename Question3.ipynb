{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d34263-bb9b-4f67-85da-ca6e8693dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in /opt/anaconda3/lib/python3.12/site-packages (4.9.7)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (16.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (2.32.3)\n",
      "Requirement already satisfied: simple-parsing in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (1.16.1)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (4.66.5)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: etils>=1.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.10.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.6.1)\n",
      "Requirement already satisfied: importlib_resources in /opt/anaconda3/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.4.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (2024.8.30)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /opt/anaconda3/lib/python3.12/site-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb9c7ba-c4a9-4035-b0cc-57ffd8df2dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words: [('the', 6283), ('and', 5680), ('to', 4766), ('i', 4653), ('of', 3757), ('you', 3142), ('my', 3118), ('a', 2987), ('that', 2569), ('in', 2362)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def load_and_preprocess_shakespeare():\n",
    "    \"\"\"\n",
    "    Downloads and preprocesses the Shakespeare dataset:\n",
    "    - Downloads text from a public URL\n",
    "    - Converts to lowercase\n",
    "    - Removes punctuation\n",
    "    - Splits text into individual words\n",
    "\n",
    "    Returns:\n",
    "    - List of words in the dataset.\n",
    "    \"\"\"\n",
    "    # Download the Shakespeare dataset\n",
    "    url = \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n",
    "    response = requests.get(url)\n",
    "    text = response.text\n",
    "\n",
    "    # Preprocess the text: lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    \n",
    "    return words\n",
    "\n",
    "def get_top_n_words(words, n):\n",
    "    \"\"\"\n",
    "    Finds the top 'n' most frequent words in a list.\n",
    "\n",
    "    Parameters:\n",
    "    - words: List of words to analyze.\n",
    "    - n: Number of top frequent words to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples with the top 'n' words and their counts.\n",
    "    \"\"\"\n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the n most common words\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Example usage\n",
    "words = load_and_preprocess_shakespeare()  # Load and preprocess the dataset\n",
    "top_n_words = get_top_n_words(words, n=10)  # Find the top 10 most frequent words\n",
    "print(\"Top 10 most frequent words:\", top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68679c6a-5ba9-4f46-9c17-9e134b37f22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
